<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 12.1.0"/>
    <title>pubget API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>


        <h2>Contents</h2>
        <ul>
  <li><a href="#installation">Installation</a></li>
  <li><a href="#quick-start">Quick Start</a></li>
  <li><a href="#usage">Usage</a>
  <ul>
    <li><a href="#step-1-downloading-articles-from-pmc">Step 1: Downloading articles from PMC</a></li>
    <li><a href="#step-2-extracting-articles-from-bulk-download">Step 2: extracting articles from bulk download</a></li>
    <li><a href="#step-3-extracting-data-from-articles">Step 3: extracting data from articles</a></li>
    <li><a href="#step-4-vectorizing-computing-tfidf-features">Step 4: vectorizing (computing TFIDF features)</a></li>
    <li><a href="#optional-step-extracting-a-new-vocabulary">Optional step: extracting a new vocabulary</a></li>
    <li><a href="#optional-step-fitting-a-neuroquery-encoding-model">Optional step: fitting a NeuroQuery encoding model</a></li>
    <li><a href="#optional-step-running-a-neurosynth-meta-analysis">Optional step: running a NeuroSynth meta-analysis</a></li>
    <li><a href="#optional-step-preparing-articles-for-annotation-with-labelbuddy">Optional step: preparing articles for annotation with <code>labelbuddy</code></a></li>
    <li><a href="#optional-step-creating-a-nimare-dataset">Optional step: creating a NiMARE dataset</a></li>
    <li><a href="#full-pipeline">Full pipeline</a></li>
    <li><a href="#logging">Logging</a></li>
  </ul></li>
  <li><a href="#writing-plugins">Writing plugins</a></li>
  <li><a href="#contributing">Contributing</a></li>
  <li><a href="#python-api">Python API</a></li>
</ul>



        <h2>API Documentation</h2>
            <ul class="memberlist">
            <li>
                    <a class="class" href="#Command">Command</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Command.__init__">Command</a>
                        </li>
                        <li>
                                <a class="variable" href="#Command.name">name</a>
                        </li>
                        <li>
                                <a class="variable" href="#Command.short_description">short_description</a>
                        </li>
                        <li>
                                <a class="function" href="#Command.edit_argument_parser">edit_argument_parser</a>
                        </li>
                        <li>
                                <a class="function" href="#Command.run">run</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ExitCode">ExitCode</a>
                            <ul class="memberlist">
                        <li>
                                <a class="variable" href="#ExitCode.COMPLETED">COMPLETED</a>
                        </li>
                        <li>
                                <a class="variable" href="#ExitCode.INCOMPLETE">INCOMPLETE</a>
                        </li>
                        <li>
                                <a class="variable" href="#ExitCode.ERROR">ERROR</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PipelineStep">PipelineStep</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PipelineStep.__init__">PipelineStep</a>
                        </li>
                        <li>
                                <a class="variable" href="#PipelineStep.name">name</a>
                        </li>
                        <li>
                                <a class="variable" href="#PipelineStep.short_description">short_description</a>
                        </li>
                        <li>
                                <a class="function" href="#PipelineStep.edit_argument_parser">edit_argument_parser</a>
                        </li>
                        <li>
                                <a class="function" href="#PipelineStep.run">run</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="function" href="#download_pmcids">download_pmcids</a>
            </li>
            <li>
                    <a class="function" href="#download_query_results">download_query_results</a>
            </li>
            <li>
                    <a class="function" href="#extract_articles">extract_articles</a>
            </li>
            <li>
                    <a class="function" href="#extract_data_to_csv">extract_data_to_csv</a>
            </li>
            <li>
                    <a class="function" href="#extract_vocabulary_to_csv">extract_vocabulary_to_csv</a>
            </li>
            <li>
                    <a class="function" href="#fit_neuroquery">fit_neuroquery</a>
            </li>
            <li>
                    <a class="function" href="#fit_neurosynth">fit_neurosynth</a>
            </li>
            <li>
                    <a class="function" href="#make_labelbuddy_documents">make_labelbuddy_documents</a>
            </li>
            <li>
                    <a class="function" href="#make_nimare_dataset">make_nimare_dataset</a>
            </li>
            <li>
                    <a class="function" href="#vectorize_corpus_to_npz">vectorize_corpus_to_npz</a>
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
pubget    </h1>

                        <div class="docstring"><p><a href="https://github.com/neuroquery/pubget/actions/workflows/testing.yml"><img src="https://github.com/neuroquery/pubget/actions/workflows/testing.yml/badge.svg" alt="build" /></a>
<a href="https://codecov.io/gh/neuroquery/pubget"><img src="https://codecov.io/gh/neuroquery/pubget/branch/main/graph/badge.svg?token=8KEBP2EN3A" alt="codecov" /></a>
<a href="https://github.com/neuroquery/pubget"><img src="https://img.shields.io/static/v1?label=&amp;message=pubget%20on%20GitHub&amp;color=black&amp;style=flat&amp;logo=github" alt="pubget on GitHub" /></a></p>

<p><b>This document describes pubget version 0.0.4</b></p>
<p><code><a href="">pubget</a></code> is a command-line tool for collecting data for large-scale
coordinate-based neuroimaging meta-analysis. It exposes some of the machinery
that was used to create the <a href="https://github.com/neuroquery/neuroquery_data">neuroquery
dataset</a>, which powers
<a href="https://neuroquery.org">neuroquery.org</a>.</p>

<p><code><a href="">pubget</a></code> downloads full-text articles from <a href="https://www.ncbi.nlm.nih.gov/pmc/">PubMed
Central</a> and extracts their text and
stereotactic coordinates. It also computes <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TFIDF
features</a> for the extracted text.</p>

<p>Besides the command-line interface, <code><a href="">pubget</a></code>'s functionality is also exposed
through its <a href="https://neuroquery.github.io/pubget/#python-api">Python API</a>.</p>

<h1 id="installation">Installation</h1>

<p>You can install <code><a href="">pubget</a></code> by running:</p>

<pre><code>pip install pubget
</code></pre>

<p>This will install the <code><a href="">pubget</a></code> Python package, as well as the <code><a href="">pubget</a></code> command.</p>

<h1 id="quick-start">Quick Start</h1>

<p>Once <code><a href="">pubget</a></code> is installed, we can download and process neuroimaging articles so
that we can later use them for meta-analysis.</p>

<pre><code>pubget run ./pubget_data -q "fMRI[title]"
</code></pre>

<p>See <code>pubget run --help</code> for a description of this command. In particular, the
<code>--n_jobs</code> option allows running some of the steps in parallel.</p>

<h1 id="usage">Usage</h1>

<p>The creation of a dataset happens in four steps:</p>

<ul>
<li>Downloading the articles in bulk from the
<a href="https://www.ncbi.nlm.nih.gov/pmc/">PMC</a> API.</li>
<li>Extracting the articles from the bulk download</li>
<li>Extracting text, stereotactic coordinates and metadata from the articles, and
storing this information in CSV files.</li>
<li>Vectorizing the text: transforming it into vectors of
<a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TFIDF</a> features.</li>
</ul>

<p>Each of these steps stores its output in a separate directory. Normally, you
will run the whole procedure in one command by invoking <code>pubget run</code>. However,
separate commands are also provided to run each step separately. Below, we
describe each step and its output. Use <code>pubget -h</code> to see a list of all available
commands and <code>pubget run -h</code> to see all the options of the main command.</p>

<p>All articles downloaded by <code><a href="">pubget</a></code> come from <a href="https://www.ncbi.nlm.nih.gov/pmc/">PubMed
Central</a>, and are therefore identified by
their PubMed Central ID (<code>pmcid</code>). Note this is not the same as the PubMed ID
(<code>pmid</code>). Not all articles in PMC have a <code>pmid</code>.</p>

<h2 id="step-1-downloading-articles-from-pmc">Step 1: Downloading articles from PMC</h2>

<p>This step is executed by the <code>pubget download</code> command. Articles to download can
be selected in 2 different ways: by using a query to search the PMC database, or
by providing an explicit list of article PMCIDs. To use a list of PMCIDs, we
must pass the path to a file containing the IDs as the <code>--pmcids_file</code>
parameter. It must contain one ID per line, for example:</p>

<pre><code>8217889
7518235
7500239
7287136
7395771
7154153
</code></pre>

<p>Note these must be PubMedCentral IDs, <em>not</em> PubMed IDs. Moreover, Some articles
can be viewed on the PubMedCentral website, but are not in the Open Access
subset. The publisher of these articles forbids downloading their full text in
XML form. Therefore, for such articles only the abstract and metadata will be
available. When we use a query instead of a PMCID list, only articles in the
Open Access subset are considered.</p>

<p>If we use a query instead, we do not use the <code>--pmcids_file</code> option, but either
<code>--query</code> or <code>--query_file</code>. Everything else works in the same way, and the rest
of this documentation relies on an example that uses a query.</p>

<p>We must first define our query, with which Pubmed Central will be searched for
articles. It can be simple such as <code>fMRI</code>, or more specific such as
<code>fMRI[Abstract] AND (2000[PubDate] : 2022[PubDate])</code>. You can build the
query using the <a href="https://www.ncbi.nlm.nih.gov/pmc/advanced">PMC advanced search
interface</a>. For more information see
<a href="https://www.ncbi.nlm.nih.gov/books/NBK3837/">the E-Utilities help</a>.
Some examples are provided in the <code><a href="">pubget</a></code> git repository, in <code>docs/example_queries</code>.</p>

<p>The query can be passed either as a string on the command-line with <code>-q</code> or
<code>--query</code> or by passing the path of a text file containing the query with <code>-f</code>
or <code>--query_file</code>.</p>

<p>If we have an Entrez API key (see details in the <a href="https://www.ncbi.nlm.nih.gov/books/NBK25497/">E-utilities
documentation</a>), we can provide it
through the <code>NQDC_API_KEY</code> environment variable or through the <code>--api_key</code>
command line argument (the latter has higher precedence).</p>

<p>We must also specify the directory in which all <code><a href="">pubget</a></code> data will be stored. It
can be provided either as a command-line argument (as in the examples below), or
by exporting the <code>NQDC_DATA_DIR</code> environment variable. Subdirectories will be
created for each different query. In the following we suppose we are storing our
data in a directory called <code>pubget_data</code>.</p>

<p>We can thus download all articles with "fMRI" in their title published in 2019 by running:</p>

<pre><code>pubget download -q "fMRI[Title] AND (2019[PubDate] : 2019[PubDate])" pubget_data
</code></pre>

<hr />

<p><strong>Note:</strong> writing the query in a file rather than passing it as an argument is
more convenient for complex queries, for example those that contain whitespace,
newlines or quotes. By storing it in a file we do not need to take care to quote
or escape characters that would be interpreted by the shell. In this case we
would store our query in a file, say <code>query.txt</code>:</p>

<pre><code>fMRI[Title] AND (2019[PubDate] : 2019[PubDate])
</code></pre>

<p>and run</p>

<pre><code>pubget download -f query.txt pubget_data
</code></pre>

<hr />

<p>After running this command, these are the contents of our data directory:</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      └── articlesets
          ├── articleset_00000.xml
          └── info.json
</code></pre>

<p><code><a href="">pubget</a></code> has created a subdirectory for this query. If we run the download again
for the same query, the same subdirectory will be reused
(<code>3c0556e22a59e7d200f00ac8219dfd6c</code> is the md5 checksum of the query). If we had
used a PMCID list instead of a query, the subdirectory name would start with
<code>pmcidList_</code> instead of <code>query_</code>.</p>

<p>Inside the query directory, the results of the bulk download are stored in the
<code>articlesets</code> directory. The articles themselves are in XML files bundling up to
500 articles called <code>articleset_*.xml</code>. Here there is only one because the
search returned less than 500 articles.</p>

<p>Some information about the download is stored in <code>info.json</code>. In particular,
<code>is_complete</code> indicates if all articles matching the search have been
downloaded. If the download was interrupted, some batches failed to download, or
the number of results was limited by using the <code>--n_docs</code> parameter,
<code>is_complete</code> will be <code>false</code> and the exit status of the program will
be 1. You may want to re-run the command before moving on to the next step if
the download is incomplete.</p>

<p>If we used a query it will be stored in <code>articlesets/query.txt</code>, and if we used
a list of PMCIDs, in <code>articlesets/requested_pmcids.txt</code>.</p>

<p>If we run the same query again, only missing batches will be downloaded. If we
want to force re-running the search and downloading the whole data we need to
remove the <code>articlesets</code> directory.</p>

<h2 id="step-2-extracting-articles-from-bulk-download">Step 2: extracting articles from bulk download</h2>

<p>This step is executed by the <code>pubget extract_articles</code> command.</p>

<p>Once our download is complete, we extract articles and store each of them in a
separate directory. To do so, we pass the <code>articlesets</code> directory created by the
<code>pubget download</code> command in step 1:</p>

<pre><code>pubget extract_articles pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/articlesets
</code></pre>

<p>This creates an <code>articles</code> subdirectory in the query directory, containing the
articles. To avoid having a large number of files in a single directory when
there are many articles, which can be problematic on some filesystems, the
articles are spread over many subdirectories. The names of these subdirectories
range from <code>000</code> to <code>fff</code> and an article goes in the subdirectory that matches
the first 3 hexidecimal digits of the md5 hash of its <code>pmcid</code>.</p>

<p>Our data directory now looks like this (with many articles ommitted for
conciseness):</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      │   ├── 019
      │   │   └── pmcid_6759467
      │   │       ├── article.xml
      │   │       └── tables
      │   │           └── tables.xml
      │   ├── 01f
      │   │   └── pmcid_6781806
      │   │       ├── article.xml
      │   │       └── tables
      │   │           ├── table_000.csv
      │   │           ├── table_000_info.json
      │   │           ├── table_001.csv
      │   │           ├── table_001_info.json
      │   │           └── tables.xml
      │   ├── ...
      │   └── info.json
      └── articlesets
</code></pre>

<p>Note that the subdirectories such as <code>articles/01f</code> can contain one or more
articles, even though the examples that appear here only contain one.</p>

<p>Each article directory, such as <code>articles/01f/pmcid_6781806</code>, contains:</p>

<ul>
<li><code>article.xml</code>: the XML file containing the full article in its original
format.</li>
<li>a <code>tables</code> subdirectory, containing:
<ul>
<li><code>tables.xml</code>: all the article's tables, each provided in 2 formats: its
original version, and converted to XHTML using the
<a href="https://docbook.org/">DocBook</a> stylesheets.</li>
<li>For each table, a CSV file containing the extracted data and a JSON file
providing information such as the table label, id, caption, and
<code>n_header_rows</code>, the number of rows at the start of the CSV that should be
treated as part of the table header.</li>
</ul></li>
</ul>

<p>If the download and article extraction were successfully run and we run the same
query again, the article extraction is skipped. If we want to force re-running
the article extraction we need to remove the <code>articles</code> directory (or the
<code>info.json</code> file it contains).</p>

<h2 id="step-3-extracting-data-from-articles">Step 3: extracting data from articles</h2>

<p>This step is executed by the <code>pubget extract_data</code> command.</p>

<p>It creates another directory that contains CSV files, containing the text,
metadata and coordinates extracted from all the articles.</p>

<p>If we use the <code>--articles_with_coords_only</code> option, only articles in which
<code><a href="">pubget</a></code> finds stereotactic coordinates are kept. The name of the resulting
directory will reflect that choice.</p>

<p>We pass the path of the <code>articles</code> directory created by <code>pubget extract_articles</code>
in the previous step to the <code>pubget extract_data</code> command:</p>

<pre><code>pubget extract_data --articles_with_coords_only pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/articles/
</code></pre>

<p>Our data directory now contains (ommitting the contents of the previous steps):</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      ├── articlesets
      └── subset_articlesWithCoords_extractedData
          ├── authors.csv
          ├── coordinates.csv
          ├── coordinate_space.csv
          ├── info.json
          ├── links.csv
          ├── metadata.csv
          └── text.csv
</code></pre>

<p>If we had not used <code>--articles_with_coords_only</code>, the new subdirectory would be
named <code>subset_allArticles_extractedData</code> instead.</p>

<ul>
<li><code>metadata.csv</code> contains one row per article, with some metadata: <code>pmcid</code>
(PubMed Central ID), <code>pmid</code> (PubMed ID), <code>doi</code>, <code>title</code>, <code>journal</code>,
<code>publication_year</code> and <code>license</code>. Note some values may be missing (for example
not all articles have a <code>pmid</code> or <code>doi</code>).</li>
<li><code>authors.csv</code> contains one row per article per author. Fields are <code>pmcid</code>,
<code>surname</code>, <code>given-names</code>.</li>
<li><code>text.csv</code> contains one row per article. The first field is the <code>pmcid</code>, and
the other fields are <code>title</code>, <code>keywords</code>, <code>abstract</code>, and <code>body</code>, and contain
the text extracted from these parts of the article.</li>
<li><code>links.csv</code> contains the external links found in the articles. The fields are
<code>pmcid</code>, <code>ext-link-type</code> (the type of link, for example "uri", "doi"), and
<code>href</code> (usually an URL).</li>
<li><code>coordinates.csv</code> contains one row for each <code>(x, y, z)</code> stereotactic
coordinate found in any article. Its fields are the <code>pmcid</code> of the article,
the table label and id the coordinates came from, and <code>x</code>, <code>y</code>, <code>z</code>.</li>
<li><code>coordinate_space.csv</code> has fields <code>pmcid</code> and <code>coordinate_space</code>. It contains
a guess about the stereotactic space coordinates are reported in, based on a
heuristic derived from <a href="https://github.com/neurosynth/ACE">neurosynth</a>.
Possible values for the space are the terms used by <code>neurosynth</code>: "MNI", "TAL"
(for Talairach space), and "UNKNOWN".</li>
</ul>

<p>The different files can be joined on the <code>pmcid</code> field.</p>

<p>If all steps up to data extraction were successfully run and we run the same
query again, the data extraction is skipped. If we want to force re-running the
data extraction we need to remove the corresponding directory (or the
<code>info.json</code> file it contains).</p>

<h2 id="step-4-vectorizing-computing-tfidf-features">Step 4: vectorizing (computing TFIDF features)</h2>

<p>This step is executed by the <code>pubget vectorize</code> command.</p>

<p>Some large-scale meta-analysis methods such as
<a href="https://neurosynth.org/">neurosynth</a> and <a href="https://neuroquery.org">neuroquery</a>
rely on <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TFIDF features</a> to
represent articles' text. The last step before we can apply these methods is
therefore to extract TFIDF features from the text we obtained in the previous
step.</p>

<p>TFIDF features rely on a predefined vocabulary (set of terms or phrases). Each
dimension of the feature vector corresponds to a term in the vocabulary and
represents the importance of that term in the encoded text. This importance is
an increasing function of the <em>term frequency</em> (the number of time the term
occurs in the text divided by the length of the text) and a decreasing function
of the <em>document frequency</em> (the total number of times the term occurs in the
whole corpus or dataset).</p>

<p>To extract the TFIDF features we must therefore choose a vocabulary.</p>

<ul>
<li>By default, <code><a href="">pubget</a></code> will download and use the vocabulary used by
<a href="https://neuroquery.org">neuroquery.org</a>.</li>
<li>If we use the <code>--extract_vocabulary</code> option, a new vocabulary is created from
the downloaded text and used for computing TFIDF features (see "extracting a
new vocabulary" below).</li>
<li>If we want to use a different vocabulary we can specify it with the
<code>--vocabulary_file</code> option. This file will be parsed as a CSV file with no
header, whose first column contains the terms. Other columns are ignored.</li>
</ul>

<p>We also pass to <code>pubget vectorize</code> the directory containing the text we want to
vectorize, created by <code>pubget extract_data</code> in step 3 (here we are using the
default vocabulary):</p>

<pre><code>pubget vectorize pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/subset_articlesWithCoords_extractedData/
</code></pre>

<p>This creates a new directory whose name reflects the data source (whether all
articles are kept or only those with coordinates) and the chosen vocabulary
(<code>e6f7a7e9c6ebc4fb81118ccabfee8bd7</code> is the md5 checksum of the contents of the
vocabulary file, concatenated with those of the vocabulary mapping file, see
"vocabulary mapping" below):</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      ├── articlesets
      ├── subset_articlesWithCoords_extractedData
      └── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
          ├── abstract_counts.npz
          ├── abstract_tfidf.npz
          ├── body_counts.npz
          ├── body_tfidf.npz
          ├── feature_names.csv
          ├── info.json
          ├── keywords_counts.npz
          ├── keywords_tfidf.npz
          ├── merged_tfidf.npz
          ├── pmcid.txt
          ├── title_counts.npz
          ├── title_tfidf.npz
          ├── vocabulary.csv
          └── vocabulary.csv_voc_mapping_identity.json
</code></pre>

<p>The extracted features are stored in <code>.npz</code> files that can be read for example
with
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.load_npz.html"><code>scipy.sparse.load_npz</code></a>.</p>

<p>These files contain matrices of shape <code>(n_docs, n_features)</code>, where <code>n_docs</code> is
the number of documents and <code>n_features</code> the number of terms in the vocabulary.
The <code>pmcid</code> corresponding to each row is found in <code>pmcid.txt</code>, and the term
corresponding to each column is found in the first column of
<code>feature_names.csv</code>.</p>

<p><code>feature_names.csv</code> has no header; the first column contains terms and the
second one contains their document frequency.</p>

<p>For each article part ("title", "keywords", "abstract" and "body"), we get the
<code>counts</code> which hold the raw counts (the number of times each word occurs in that
section), and the <code>tfidf</code> which hold the TFIDF features (the counts divided by
article length and log document frequency). Moreover, <code>merged_tfidf</code> contains
the mean TFIDF computed across all article parts.</p>

<p>If all steps up to vectorization were successfully run and we run the same query
again, the vectorization is skipped. If we want to force re-running the
vectorization we need to remove the corresponding directory (or the <code>info.json</code>
file it contains).</p>

<h3 id="vocabulary-mapping-collapsing-redundant-words">Vocabulary mapping: collapsing redundant words</h3>

<p>It is possible to instruct the tokenizer (that extracts words from text) to
collapse some pairs of terms that have the same meaning but different spellings,
such as "brainstem" and "brain stem".</p>

<p>This is done through a JSON file that contains a mapping of the form <code>{term:
replacement}</code>. For example if it contains <code>{"brain stem": "brainstem"}</code>, "brain
stem" will be discarded from the vocabulary and every occurrence of "brain stem"
will be counted as an occurrence of "brainstem" instead. To be found by <code><a href="">pubget</a></code>,
this vocabulary mapping file must be in the same directory as the vocabulary
file, and its name must be the vocabulary file's name with
<code>_voc_mapping_identity.json</code> appended: for example <code>vocabulary.csv</code>,
<code>vocabulary.csv_voc_mapping_identity.json</code>.</p>

<p>When a vocabulary mapping is provided, a shorter vocabulary is therefore created
by removing redundant words. The TFIDF and word counts computed by <code><a href="">pubget</a></code>
correspond to the shorter vocabulary, which is stored along with its document
frequencies in <code>feature_names.csv</code>.</p>

<p><code>vocabulary.csv</code> contains the document frequencies of the original (full,
longer) vocabulary. A <code>vocabulary.csv_voc_mapping_identity.json</code> file is always
created by <code><a href="">pubget</a></code>, but if no vocabulary mapping was used, that file contains an
empty mapping (<code>{}</code>) and <code>vocabulary.csv</code> and <code>feature_names.csv</code> are identical.</p>

<p>The vocabulary mapping is primarily used by the <code>neuroquery</code> package and its
tokenization pipeline, and you can safely ignore this – just remember that the
file providing the terms corresponding to the TFIDF <em>features</em> is
<code>feature_names.csv</code>.</p>

<h2 id="optional-step-extracting-a-new-vocabulary">Optional step: extracting a new vocabulary</h2>

<p>This step is executed by the <code>pubget extract_vocabulary</code> command.
When running the full pipeline this step is optional: we must use
the <code>--extract_vocabulary</code> option for it to be executed.</p>

<p>It builds a vocabulary of all the words and 2-grams (groups of 2 
words) that appear in the downloaded text, and computes their document frequency
(the proportion of documents in which a term appears).</p>

<pre><code>pubget extract_vocabulary pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/subset_articlesWithCoords_extractedData
</code></pre>

<p>The vocabulary is stored in a csv file in a new directory. There is no header
and the 2 columns are the term and its document frequency.</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      ├── articlesets
      ├── subset_articlesWithCoords_extractedData
      ├── subset_articlesWithCoords_extractedVocabulary
      │   ├── info.json
      │   └── vocabulary.csv
      └── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>When running the whole pipeline (<code>pubget run</code>), if we use the
<code>--extract_vocabulary</code> option and do not provide an explicit value for
<code>--vocabulary_file</code>, the freshly-extracted vocabulary is used instead of the
default <code>neuroquery</code> one for computing TFIDF features.</p>

<h2 id="optional-step-fitting-a-neuroquery-encoding-model">Optional step: fitting a NeuroQuery encoding model</h2>

<p>This step is executed by the <code>pubget fit_neuroquery</code> command. When running the
full pipeline it is optional: we must use the <code>--fit_neuroquery</code> option
for it to be executed.</p>

<p>In this step, once the TFIDF features and the coordinates have been extracted
from downloaded articles, they are used to train a NeuroQuery encoding model --
the same type of model that is exposed at
<a href="https://neuroquery.org">neuroquery.org</a>. Details about this model are provided
in <a href="https://elifesciences.org/articles/53385">the NeuroQuery paper</a> and the
documentation for the <a href="https://github.com/neuroquery/neuroquery">neuroquery
package</a>.</p>

<p>Note: for this model to give good results a large dataset is needed, ideally close to 10,000 articles (with coordinates).</p>

<p>We pass the <code>_vectorizedText</code> directory created by <code>pubget vectorize</code>:</p>

<pre><code>pubget fit_neuroquery pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>This creates a directory whose name ends with <code>_neuroqueryModel</code>:</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      ├── articlesets
      ├── subset_articlesWithCoords_extractedData
      ├── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_neuroqueryModel
      │   ├── app.py
      │   ├── info.json
      │   ├── neuroquery_model
      │   │   ├── corpus_metadata.csv
      │   │   ├── corpus_tfidf.npz
      │   │   ├── mask_img.nii.gz
      │   │   ├── regression
      │   │   │   ├── coef.npy
      │   │   │   ├── intercept.npy
      │   │   │   ├── M.npy
      │   │   │   ├── original_n_features.npy
      │   │   │   ├── residual_var.npy
      │   │   │   └── selected_features.npy
      │   │   ├── smoothing
      │   │   │   ├── smoothing_weight.npy
      │   │   │   └── V.npy
      │   │   ├── vocabulary.csv
      │   │   └── vocabulary.csv_voc_mapping_identity.json
      │   ├── README.md
      │   └── requirements.txt
      └── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>You do not need to care about the contents of the <code>neuroquery_model</code> subdirectory, that is data used by the <code>neuroquery</code> package.
Just know that it can be used to initialize a <code>neuroquery.NeuroQueryModel</code> with:</p>

<div class="pdoc-code codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">neuroquery</span> <span class="kn">import</span> <span class="n">NeuroQueryModel</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NeuroQueryModel</span><span class="o">.</span><span class="n">from_data_dir</span><span class="p">(</span><span class="s2">&quot;neuroquery_model&quot;</span><span class="p">)</span>
</code></pre></div>

<p>The <code>neuroquery</code> documentation provides information and examples on how to use this model.</p>

<h3 id="visualizing-the-newly-trained-model-in-an-interactive-web-page">Visualizing the newly trained model in an interactive web page</h3>

<p>It is easy to interact with the model through a small web (Flask) application.
From inside the <code>[...]_neuroqueryModel</code> directory, just run <code>pip install -r requirements.txt</code> to install <code>flask</code>, <code>nilearn</code> and <code>neuroquery</code>.
Then run <code>flask run</code> and point your web browser to <code>https://localhost:5000</code>: you can play with a local, simplified version of <a href="https://neuroquery.org">neuroquery.org</a> built with the data we just downloaded.</p>

<h2 id="optional-step-running-a-neurosynth-meta-analysis">Optional step: running a NeuroSynth meta-analysis</h2>

<p>This step is executed by the <code>pubget fit_neurosynth</code> command. When running the
full pipeline it is optional: we must use the <code>--fit_neurosynth</code> option for it
to be executed.</p>

<p>In this step, once the TFIDF features and the coordinates have been extracted
from downloaded articles, they are used to run meta-analyses using NeuroSynth's
"association test" method: a Chi-squared test of independence between voxel
activation and term occurrences. See <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3146590/">the NeuroSynth
paper</a> and
<a href="https://neurosynth.org">neurosynth.org</a>, as well as the
<a href="https://github.com/neurosynth/neurosynth">neurosynth</a> and
<a href="https://nimare.readthedocs.io/">NiMARE</a> documentation pages for more
information.</p>

<p>We pass the <code>_vectorizedText</code> directory created by <code>pubget vectorize</code>:</p>

<pre><code>pubget fit_neurosynth pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>This creates a directory whose name ends with <code>_neurosynthResults</code>:</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      ├── articlesets
      ├── subset_articlesWithCoords_extractedData
      ├── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_neurosynthResults
      │   ├── app.py
      │   ├── info.json
      │   ├── metadata.csv
      │   ├── neurosynth_maps
      │   │   ├── aberrant.nii.gz
      │   │   ├── abilities.nii.gz
      │   │   ├── ability.nii.gz
      │   │   └── ...
      │   ├── README.md
      │   ├── requirements.txt
      │   ├── terms.csv
      │   └── tfidf.npz
      └── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>The meta-analytic maps for all the terms in the vocabulary can be found in the
<code>neurosynth_maps</code> subdirectory.</p>

<h3 id="visualizing-the-meta-analytic-maps-in-an-interactive-web-page">Visualizing the meta-analytic maps in an interactive web page</h3>

<p>It is easy to interact with the NeuroSynth maps through a small web (Flask)
application. From inside the <code>[...]_neurosynthResults</code> directory, just run <code>pip
install -r requirements.txt</code> to install <code>flask</code> and other dependencies. Then run
<code>flask run</code> and point your web browser to <code>https://localhost:5000</code>: you can
search for a term and see the corresponding brain map and the documents that
mention it.</p>

<h2 id="optional-step-preparing-articles-for-annotation-with-labelbuddy">Optional step: preparing articles for annotation with <code>labelbuddy</code></h2>

<p>This step is executed by the <code>pubget extract_labelbuddy_data</code> command.
When running the full pipeline this step is optional: we must use
the <code>--labelbuddy</code> or <code>--labelbuddy_part_size</code> option for it to be executed.</p>

<p>It prepares the articles whose data was extracted for annotation with
<a href="https://jeromedockes.github.io/labelbuddy/">labelbuddy</a>.</p>

<p>We pass the <code>_extractedData</code> directory created by <code>pubget extract_data</code>:</p>

<pre><code>pubget extract_labelbuddy_data pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/subset_articlesWithCoords_extractedData
</code></pre>

<p>This creates a directory whose name ends with <code>labelbuddyData</code> containing the batches of documents in JSONL format (in this case there is a single batch):</p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      ├── articlesets
      ├── subset_articlesWithCoords_extractedData
      ├── subset_articlesWithCoords_labelbuddyData
      │   ├── documents_00001.jsonl
      │   └── info.json
      └── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>The documents can be imported into <code>labelbuddy</code> using the GUI or with:</p>

<pre><code>labelbuddy mydb.labelbuddy --import-docs documents_00001.jsonl
</code></pre>

<p>See the <a href="https://jeromedockes.github.io/labelbuddy/labelbuddy/current/documentation/">labelbuddy
documentation</a>
for details.</p>

<h2 id="optional-step-creating-a-nimare-dataset">Optional step: creating a NiMARE dataset</h2>

<p>This step is executed by the <code>pubget extract_nimare_data</code> command. When running
the full pipeline this step is optional: we must use the <code>--nimare</code> option for
it to be executed.</p>

<p>It creates a <a href="https://nimare.readthedocs.io/">NiMARE</a> dataset for the extracted
data in JSON format. See the NiMARE
<a href="https://nimare.readthedocs.io/en/latest/generated/nimare.dataset.Dataset.html#nimare.dataset.Dataset">documentation</a>
for details.</p>

<p>We pass the <code>_vectorizedText</code> directory created by <code>pubget vectorize</code>:</p>

<pre><code>pubget extract_nimare_data pubget_data/query_3c0556e22a59e7d200f00ac8219dfd6c/subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>The resulting directory contains a <code>nimare_dataset.json</code> file that can be used to initialize a <code>nimare.Dataset</code>. </p>

<pre><code>· pubget_data
  └── query_3c0556e22a59e7d200f00ac8219dfd6c
      ├── articles
      ├── articlesets
      ├── subset_articlesWithCoords_extractedData
      ├── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_nimareDataset
      │   ├── info.json
      │   └── nimare_dataset.json
      └── subset_articlesWithCoords-voc_e6f7a7e9c6ebc4fb81118ccabfee8bd7_vectorizedText
</code></pre>

<p>Using this option requires installing NiMARE, which is not installed by default
with <code><a href="">pubget</a></code>. To use this option, install NiMARE separately with</p>

<pre><code>pip install nimare
</code></pre>

<p>or install <code><a href="">pubget</a></code> with</p>

<pre><code>pip install "pubget[nimare]"
</code></pre>

<h2 id="full-pipeline">Full pipeline</h2>

<p>We can run all steps in one command by using <code>pubget run</code>.</p>

<p>The full procedure described above could be run by executing:</p>

<pre><code>pubget run -q "fMRI[Title] AND (2019[PubDate] : 2019[PubDate])" \
    --articles_with_coords_only                               \
    pubget_data
</code></pre>

<p>(The output directory, <code>pubget_data</code>, could also be provided by exporting the
<code>NQDC_DATA_DIR</code> environment variable instead of passing it on the command line.)</p>

<p>If we also want to apply the optional steps:</p>

<pre><code>pubget run -q "fMRI[Title] AND (2019[PubDate] : 2019[PubDate])" \
    --articles_with_coords_only                               \
    --fit_neuroquery                                          \
    --labelbuddy                                              \
    --nimare                                                  \
    pubget_data
</code></pre>

<p>(remember that <code>--nimare</code> requires NiMARE to be installed).</p>

<p>Here also, steps that had already been completed are skipped; we need to remove
the corresponding directories if we want to force running these steps again.</p>

<p>See <code>pubget run --help</code> for a description of all options.</p>

<h2 id="logging">Logging</h2>

<p>By default <code><a href="">pubget</a></code> commands report their progress by writing to the standard
streams. In addition, they can write log files if we provide the <code>--log_dir</code>
command-line argument, or if we define the <code>NQDC_LOG_DIR</code> environment variable
(the command-line argument has higher precedence). If this log directory is
specified, a new log file with a timestamp is created and all the output is
written there as well.</p>

<h1 id="writing-plugins">Writing plugins</h1>

<p>It is possible to write plugins and define <a href="https://setuptools.pypa.io/en/latest/userguide/entry_point.html">entry
points</a> to add
functionality that is automatically executed when <code><a href="">pubget</a></code> is run.</p>

<p>The name of the entry point should be <code>pubget.plugin_actions</code>. It must be
a function taking no arguments and returning a dictionary with keys
<code>pipeline_steps</code> and <code>commands</code>. The corresponding values must be lists
of processing step objects, that must implement the interface defined by
<code><a href="#PipelineStep">pubget.PipelineStep</a></code> and <code><a href="#Command">pubget.Command</a></code> respectively (their types do not need to
inherit from these classes).</p>

<p>All steps in <code>pipeline_steps</code> will be run when <code>pubget run</code> is used. All steps in
<code>standalone_steps</code> will be added as additional pubget commands; for example if the
<code>name</code> of a standalone step is <code>my_plugin</code>, the <code>pubget my_plugin</code> command will
become available.</p>

<p>An example plugin that can be used as a template, and more details, are provided
in the <code><a href="">pubget</a></code> git repository, in <code>docs/example_plugin</code>.</p>

<h1 id="contributing">Contributing</h1>

<p>Feedback and contributions are welcome. Development happens at the
<a href="https://github.com/neuroquery/pubget">pubget GitHub repositiory</a>.
To install the dependencies required for development, from the directory where you cloned <code><a href="">pubget</a></code>, run:</p>

<pre><code>pip install -e ".[dev]"
</code></pre>

<p>The tests can be run with <code>make test_all</code>, or <code>make test_coverage</code> to report
test coverage. The documentation can be rendered with <code>make doc</code>. <code>make
run_full_pipeline</code> runs the full <code><a href="">pubget</a></code> pipeline on a query returning a
realistic number of results (<code>fMRI[title]</code>).</p>

<h1 id="python-api">Python API</h1>

<p><code><a href="">pubget</a></code> is mostly intended for use as a command-line tool. However, it is also a
Python package and its functionality can be used in Python programs. The Python
API closely reflects the command-line programs described above.</p>

<p>The Python API is described on the <code><a href="">pubget</a></code> <a href="https://neuroquery.github.io/pubget/#python-api">website</a>.</p>
</div>

                
                
                
            </section>
                <section id="Command">
                    <div class="attr class">
            
    <span class="def">class</span>
    <span class="name">Command</span>:

        
    </div>
    <a class="headerlink" href="#Command"></a>
    
            <div class="docstring"><p>An <code><a href="">pubget</a></code> subcommand.</p>
</div>


                            <div id="Command.__init__" class="classattr">
                                <div class="attr function">
            
        <span class="name">Command</span><span class="signature pdoc-code condensed">()</span>

        
    </div>
    <a class="headerlink" href="#Command.__init__"></a>
    
    

                            </div>
                            <div id="Command.name" class="classattr">
                                <div class="attr variable">
            <span class="name">name</span><span class="annotation">: str</span>

        
    </div>
    <a class="headerlink" href="#Command.name"></a>
    
            <div class="docstring"><p>Name for this command.</p>
</div>


                            </div>
                            <div id="Command.short_description" class="classattr">
                                <div class="attr variable">
            <span class="name">short_description</span><span class="annotation">: str</span>

        
    </div>
    <a class="headerlink" href="#Command.short_description"></a>
    
            <div class="docstring"><p>A short description of the command.</p>
</div>


                            </div>
                            <div id="Command.edit_argument_parser" class="classattr">
                                <div class="attr function">
                    <div class="decorator">@abstractmethod</div>

        <span class="def">def</span>
        <span class="name">edit_argument_parser</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">argument_parser</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">_ArgumentGroup</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#Command.edit_argument_parser"></a>
    
            <div class="docstring"><p>Add arguments needed by this command to parser.</p>
</div>


                            </div>
                            <div id="Command.run" class="classattr">
                                <div class="attr function">
                    <div class="decorator">@abstractmethod</div>

        <span class="def">def</span>
        <span class="name">run</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span></span><span class="return-annotation">) -> <span class="n"><a href="#ExitCode">pubget.ExitCode</a></span>:</span></span>

        
    </div>
    <a class="headerlink" href="#Command.run"></a>
    
            <div class="docstring"><p>Execute this command. Return exit code.</p>
</div>


                            </div>
                </section>
                <section id="ExitCode">
                    <div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ExitCode</span><wbr>(<span class="base">enum.IntEnum</span>):

        
    </div>
    <a class="headerlink" href="#ExitCode"></a>
    
            <div class="docstring"><p>Exit code for a processing step.</p>
</div>


                            <div id="ExitCode.COMPLETED" class="classattr">
                                <div class="attr variable">
            <span class="name">COMPLETED</span><span class="default_value"> = &lt;<a href="#ExitCode.COMPLETED">ExitCode.COMPLETED</a>: 0&gt;</span>

        
    </div>
    <a class="headerlink" href="#ExitCode.COMPLETED"></a>
    
    

                            </div>
                            <div id="ExitCode.INCOMPLETE" class="classattr">
                                <div class="attr variable">
            <span class="name">INCOMPLETE</span><span class="default_value"> = &lt;<a href="#ExitCode.INCOMPLETE">ExitCode.INCOMPLETE</a>: 1&gt;</span>

        
    </div>
    <a class="headerlink" href="#ExitCode.INCOMPLETE"></a>
    
    

                            </div>
                            <div id="ExitCode.ERROR" class="classattr">
                                <div class="attr variable">
            <span class="name">ERROR</span><span class="default_value"> = &lt;<a href="#ExitCode.ERROR">ExitCode.ERROR</a>: 2&gt;</span>

        
    </div>
    <a class="headerlink" href="#ExitCode.ERROR"></a>
    
    

                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>enum.Enum</dt>
                                <dd id="ExitCode.name" class="variable">name</dd>
                <dd id="ExitCode.value" class="variable">value</dd>

            </div>
            <div><dt>builtins.int</dt>
                                <dd id="ExitCode.conjugate" class="function">conjugate</dd>
                <dd id="ExitCode.bit_length" class="function">bit_length</dd>
                <dd id="ExitCode.bit_count" class="function">bit_count</dd>
                <dd id="ExitCode.to_bytes" class="function">to_bytes</dd>
                <dd id="ExitCode.from_bytes" class="function">from_bytes</dd>
                <dd id="ExitCode.as_integer_ratio" class="function">as_integer_ratio</dd>
                <dd id="ExitCode.real" class="variable">real</dd>
                <dd id="ExitCode.imag" class="variable">imag</dd>
                <dd id="ExitCode.numerator" class="variable">numerator</dd>
                <dd id="ExitCode.denominator" class="variable">denominator</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="PipelineStep">
                    <div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PipelineStep</span>:

        
    </div>
    <a class="headerlink" href="#PipelineStep"></a>
    
            <div class="docstring"><p>An individual step in the <code><a href="">pubget</a></code> pipeline (<code>pubget run</code>).</p>
</div>


                            <div id="PipelineStep.__init__" class="classattr">
                                <div class="attr function">
            
        <span class="name">PipelineStep</span><span class="signature pdoc-code condensed">()</span>

        
    </div>
    <a class="headerlink" href="#PipelineStep.__init__"></a>
    
    

                            </div>
                            <div id="PipelineStep.name" class="classattr">
                                <div class="attr variable">
            <span class="name">name</span><span class="annotation">: str</span>

        
    </div>
    <a class="headerlink" href="#PipelineStep.name"></a>
    
            <div class="docstring"><p>Name for this step.</p>
</div>


                            </div>
                            <div id="PipelineStep.short_description" class="classattr">
                                <div class="attr variable">
            <span class="name">short_description</span><span class="annotation">: str</span>

        
    </div>
    <a class="headerlink" href="#PipelineStep.short_description"></a>
    
            <div class="docstring"><p>A short description of the processing step.</p>
</div>


                            </div>
                            <div id="PipelineStep.edit_argument_parser" class="classattr">
                                <div class="attr function">
                    <div class="decorator">@abstractmethod</div>

        <span class="def">def</span>
        <span class="name">edit_argument_parser</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">argument_parser</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">_ArgumentGroup</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#PipelineStep.edit_argument_parser"></a>
    
            <div class="docstring"><p>Add arguments needed by this step to parser.</p>
</div>


                            </div>
                            <div id="PipelineStep.run" class="classattr">
                                <div class="attr function">
                    <div class="decorator">@abstractmethod</div>

        <span class="def">def</span>
        <span class="name">run</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span>,</span><span class="param">	<span class="n">previous_steps_output</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">],</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#PipelineStep.run"></a>
    
            <div class="docstring"><p>Execute this step. Return resulting directory and exit code.</p>
</div>


                            </div>
                </section>
                <section id="download_pmcids">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">download_pmcids</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">pmcids</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>,</span><span class="param">	<span class="n">data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="o">*</span>,</span><span class="param">	<span class="n">n_docs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">retmax</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span>,</span><span class="param">	<span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#download_pmcids"></a>
    
            <div class="docstring"><p>Download articles in a provided list of PMCIDs.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>pmcids</strong>: List of PubMed Central IDs to download.</li>
<li><strong>data_dir</strong>: Path to the directory where all pubget data is stored; a subdirectory
will be created for this download.</li>
<li><strong>n_docs</strong>: Approximate maximum number of articles to download. By default, all
results returned for the search are downloaded. If n_docs is
specified, at most n_docs rounded up to the nearest multiple of
<code>retmax</code> articles will be downloaded.</li>
<li><strong>retmax</strong>: Batch size -- number of articles that are downloaded per request.</li>
<li><strong>api_key</strong>: API key for the Entrez E-utilities (see <a href="https://www.ncbi.nlm.nih.gov/books/NBK25497/">the E-utilities
help</a>). If the API
key is provided, it is included in all requests to the Entrez
E-utilities.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory that was created in which downloaded data is stored.</li>
<li><strong>exit_code</strong>: COMPLETED if all articles have been successfully downloaded and
INCOMPLETE or ERROR otherwise. Used by the <code><a href="">pubget</a></code> command-line
interface.</li>
</ul>
</div>


                </section>
                <section id="download_query_results">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">download_query_results</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">query</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="o">*</span>,</span><span class="param">	<span class="n">n_docs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">retmax</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span>,</span><span class="param">	<span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#download_query_results"></a>
    
            <div class="docstring"><p>Download articles matching a query from PubMedCentral.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>query</strong>: Search term for querying the PMC database. You can build the query
using the <a href="https://www.ncbi.nlm.nih.gov/pmc/advanced">PMC advanced search
interface</a>. For more
information see <a href="https://www.ncbi.nlm.nih.gov/books/NBK3837/">the E-Utilities
help</a>.</li>
<li><strong>data_dir</strong>: Path to the directory where all pubget data is stored; a subdirectory
will be created for this download.</li>
<li><strong>n_docs</strong>: Approximate maximum number of articles to download. By default, all
results returned for the search are downloaded. If n_docs is
specified, at most n_docs rounded up to the nearest multiple of
<code>retmax</code> articles will be downloaded.</li>
<li><strong>retmax</strong>: Batch size -- number of articles that are downloaded per request.</li>
<li><strong>api_key</strong>: API key for the Entrez E-utilities (see <a href="https://www.ncbi.nlm.nih.gov/books/NBK25497/">the E-utilities
help</a>). If the API
key is provided, it is included in all requests to the Entrez
E-utilities.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory that was created in which downloaded data is stored.</li>
<li><strong>exit_code</strong>: COMPLETED if all articles have been successfully downloaded and
INCOMPLETE or ERROR otherwise. Used by the <code><a href="">pubget</a></code> command-line
interface.</li>
</ul>
</div>


                </section>
                <section id="extract_articles">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">extract_articles</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">articlesets_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#extract_articles"></a>
    
            <div class="docstring"><p>Extract articles from bulk download files.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>articlesets_dir</strong>: Directory containing the downloaded files. It is a directory created by
<code>pubget.download_articles_for_query</code>: it is named <code>articlesets</code> and it
contains the bulk download files <code>articleset_00000.xml</code>,
<code>articleset_00001.xml</code>, etc.</li>
<li><strong>output_dir</strong>: Directory where to store the extracted articles. If not specified, a
sibling directory of <code>articlesets_dir</code> called <code>articles</code> will be used.</li>
<li><strong>n_jobs</strong>: Number of processes to run in parallel. <code>-1</code> means using all
processors.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which articles are stored. To avoid having a very
large number of files in one directory, subdirectories with names
ranging from <code>000</code> to <code>fff</code> are created. Each article is stored in the
subdirectory that matches the first hexadecimal digits of the md5
checksum of its PMC id. Therefore the contents of the <code>articles</code>
directory might look like:</li>
</ul>

<pre><code>· articles
  ├── 001
  │   └── pmcid_4150635
  └── 00b
      ├── pmcid_2568959
      └── pmcid_5102699
</code></pre>

<p>Each article gets its own subdirectory, containing the article's XML
and its tables.</p>

<ul>
<li><strong>exit_code</strong>: COMPLETED if the download in <code>articlesets_dir</code> was complete and the
article extraction finished normally and INCOMPLETE otherwise. Used by
the <code><a href="">pubget</a></code> command-line interface.</li>
</ul>
</div>


                </section>
                <section id="extract_data_to_csv">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">extract_data_to_csv</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">articles_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="o">*</span>,</span><span class="param">	<span class="n">articles_with_coords_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#extract_data_to_csv"></a>
    
            <div class="docstring"><p>Extract text and coordinates from articles and store in csv files.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>articles_dir</strong>: Directory containing the article files. It is a directory created by
<code><a href="#extract_articles">pubget.extract_articles</a></code>: it is named <code>articles</code> and contains
subdirectories <code>000</code> - <code>fff</code>, each of which contains articles stored in
XML files.</li>
<li><strong>output_dir</strong>: Directory in which to store the extracted data. If not specified, a
sibling directory of <code>articles_dir</code> is used. Its name is
<code>subset_allArticles_extractedData</code> or
<code>subset_articlesWithCoords_extractedData</code>, depending on the value of
<code>articles_with_coords_only</code>.</li>
<li><strong>articles_with_coords_only</strong>: If True, articles that contain no stereotactic coordinates are ignored.</li>
<li><strong>n_jobs</strong>: Number of processes to run in parallel. <code>-1</code> means using all
processors.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which extracted data is stored.</li>
<li><strong>exit_code</strong>: COMPLETED if previous (article extraction) step was complete and this
step (data extraction) finished normally as well. Used by the <code><a href="">pubget</a></code>
command-line interface.</li>
</ul>
</div>


                </section>
                <section id="extract_vocabulary_to_csv">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">extract_vocabulary_to_csv</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">extracted_data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#extract_vocabulary_to_csv"></a>
    
            <div class="docstring"><p>Extract vocabulary and document frequencies and write to csv.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>extracted_data_dir</strong>: The directory containing the text of articles to vectorize. It is a
directory created by <code><a href="#extract_data_to_csv">pubget.extract_data_to_csv</a></code>: it contains a file
named <code>text.csv</code> with fields <code>pmcid</code>, <code>title</code>, <code>keywords</code>, <code>abstract</code>,
<code>body</code>.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which the vocabulary is stored.</li>
<li><strong>exit_code</strong>: COMPLETED if previous (data extraction) step was complete and this step
(vocabulary extraction) finished normally as well. Used by the <code><a href="">pubget</a></code>
command-line interface.</li>
</ul>
</div>


                </section>
                <section id="fit_neuroquery">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit_neuroquery</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">tfidf_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">extracted_data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#fit_neuroquery"></a>
    
            <div class="docstring"><p>Fit a NeuroQuery encoder.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>vectorized_dir</strong>: The directory containing the vectorized text (TFIDF features). It is
the directory created by <code><a href="#vectorize_corpus_to_npz">pubget.vectorize_corpus_to_npz</a></code> using
<code>extracted_data_dir</code> as input.</li>
<li><strong>extracted_data_dir</strong>: The directory containing extracted metadata and coordinates. It is a
directory created by <code><a href="#extract_data_to_csv">pubget.extract_data_to_csv</a></code>. If <code>None</code>, this
function looks for a sibling directory of the <code>vectorized_dir</code> whose
name ends with <code>_extractedData</code>.</li>
<li><strong>output_dir</strong>: Directory in which to store the NeuroQuery model. If not specified, a
sibling directory of <code>vectorized_dir</code> whose name ends with
<code>_neuroqueryModel</code> is created. It will contain a <code>neuroquery_model</code>
subdirectory that can be loaded with
<code>neuroquery.NeuroQueryModel.from_data_dir</code></li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which the neuroquery model is stored.</li>
<li><strong>exit_code</strong>: COMPLETED if the neuroquery model was fitted and previous steps were
complete and INCOMPLETE otherwise. Used by the <code><a href="">pubget</a></code> command-line
interface.</li>
</ul>
</div>


                </section>
                <section id="fit_neurosynth">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit_neurosynth</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">tfidf_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">extracted_data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#fit_neurosynth"></a>
    
            <div class="docstring"><p>Run a NeuroSyth-style meta-analysis.</p>

<p>(Chi2 test of independence between term occurrence and voxel activation).</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>vectorized_dir</strong>: The directory containing the vectorized text (TFIDF features). It is
the directory created by <code><a href="#vectorize_corpus_to_npz">pubget.vectorize_corpus_to_npz</a></code> using
<code>extracted_data_dir</code> as input.</li>
<li><strong>extracted_data_dir</strong>: The directory containing extracted metadata and coordinates. It is a
directory created by <code><a href="#extract_data_to_csv">pubget.extract_data_to_csv</a></code>. If <code>None</code>, this
function looks for a sibling directory of the <code>vectorized_dir</code> whose
name ends with <code>_extractedData</code>.</li>
<li><strong>output_dir</strong>: Directory in which to store the NeuroSynth maps. If not specified, a
sibling directory of <code>vectorized_dir</code> whose name ends with
<code>_neurosynthResults</code> is created. It will contain the images (of Z
values) resulting from the analysis.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which the meta-analysis maps are stored.</li>
<li><strong>exit_code</strong>: COMPLETED if the analysis ran successfully and previous steps were
complete and INCOMPLETE otherwise. Used by the <code><a href="">pubget</a></code> command-line
interface.</li>
</ul>
</div>


                </section>
                <section id="make_labelbuddy_documents">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">make_labelbuddy_documents</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">extracted_data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">part_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">500</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#make_labelbuddy_documents"></a>
    
            <div class="docstring"><p>Prepare articles for annotation with labelbuddy.</p>

<p>The documents are prepared in JSONL format, with <code>part_size</code> documents in
each <code>.jsonl</code> file. They can thus be imported into labelbuddy with, for
example: <code>labelbuddy mydb.labelbuddy --import-docs documents_00001.jsonl</code>.</p>

<p>See the
<a href="https://jeromedockes.github.io/labelbuddy/">labelbuddy documentation</a>
for details.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>extracted_data_dir</strong>: The directory containing extracted text and metadata. It is a directory
created by <code><a href="#extract_data_to_csv">pubget.extract_data_to_csv</a></code>.</li>
<li><strong>output_dir</strong>: Directory in which to store the created data. If not specified, a
sibling directory of <code>extracted_data_dir</code> whose name ends with
<code>_labelbuddyData</code> is created.</li>
<li><strong>part_size</strong>: Number of articles stored in each <code>.jsonl</code> file.
If <code>None</code>, put all articles in one file.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which the prepared documents are stored.</li>
<li><strong>exit_code</strong>: COMPLETED if previous steps were complete and INCOMPLETE otherwise.
Used by the <code><a href="">pubget</a></code> command-line interface.</li>
</ul>
</div>


                </section>
                <section id="make_nimare_dataset">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">make_nimare_dataset</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">vectorized_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">extracted_data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">],</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#make_nimare_dataset"></a>
    
            <div class="docstring"><p>Create a NiMARE JSON dataset from data collected by <code><a href="">pubget</a></code>.</p>

<p>See the <a href="https://nimare.readthedocs.io/">NiMARE documentation</a> for details.
This function requires <code>nimare</code> to be installed.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>vectorized_dir</strong>: The directory containing the vectorized text (TFIDF features). It is
the directory created by <code><a href="#vectorize_corpus_to_npz">pubget.vectorize_corpus_to_npz</a></code> using
<code>extracted_data_dir</code> as input.</li>
<li><strong>extracted_data_dir</strong>: The directory containing extracted metadata and coordinates. It is a
directory created by <code><a href="#extract_data_to_csv">pubget.extract_data_to_csv</a></code>. If <code>None</code>, this
function looks for a sibling directory of the <code>vectorized_dir</code> whose
name ends with <code>_extractedData</code>.</li>
<li><strong>output_dir</strong>: Directory in which to store the extracted data. If not specified, a
sibling directory of <code>vectorized_dir</code> whose name ends with
<code>_nimareDataset</code> is created.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which the NiMARE dataset is stored. It contains a
<code>nimare_dataset.json</code> file.</li>
<li><strong>exit_code</strong>: COMPLETED if previous steps were complete and the NiMARE dataset was
created, INCOMPLETE if previous steps were incomplete, ERROR if NiMARE
is not installed. Used by the <code><a href="">pubget</a></code> command-line interface.</li>
</ul>
</div>


                </section>
                <section id="vectorize_corpus_to_npz">
                    <div class="attr function">
            
        <span class="def">def</span>
        <span class="name">vectorize_corpus_to_npz</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">extracted_data_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">output_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">vocabulary</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_vectorization</span><span class="o">.</span><span class="n">Vocabulary</span><span class="p">]</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Vocabulary</span><span class="o">.</span><span class="n">NEUROQUERY_VOCABULARY</span><span class="p">:</span> <span class="s1">&#39;https://github.com/neuroquery/neuroquery_data/blob/main/neuroquery_model/vocabulary.csv&#39;</span><span class="o">&gt;</span>,</span><span class="param">	<span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">pubget</span><span class="o">.</span><span class="n">_ExitCode</span><span class="p">]</span>:</span></span>

        
    </div>
    <a class="headerlink" href="#vectorize_corpus_to_npz"></a>
    
            <div class="docstring"><p>Compute word counts and TFIDF features and store them in <code>.npz</code> files.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>extracted_data_dir</strong>: The directory containing the text of articles to vectorize. It is a
directory created by <code><a href="#extract_data_to_csv">pubget.extract_data_to_csv</a></code>: it contains a file
named <code>text.csv</code> with fields <code>pmcid</code>, <code>title</code>, <code>keywords</code>, <code>abstract</code>,
<code>body</code>.</li>
<li><strong>output_dir</strong>: The directory in which to store the results. If not specified, a
sibling directory of <code>extracted_data_dir</code> will be used. Its name will
end with <code>-voc_&lt;md5 checksum of the vocabulary&gt;_vectorizedText</code>.</li>
<li><strong>vocabulary</strong>: A file containing the vocabulary used to vectorize text, with one term
or phrase per line. Each dimension in the output will correspond to the
frequency of one entry in this vocabulary. By default, the vocabulary
used by <a href="https://neuroquery.org">https://neuroquery.org</a> will be downloaded and used.</li>
<li><strong>n_jobs</strong>: Number of processes to run in parallel. <code>-1</code> means using all
processors.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>output_dir</strong>: The directory in which the vectorized data is stored.</li>
<li><strong>exit_code</strong>: COMPLETED if previous (data extraction) step was complete and this step
(vectorization) finished normally as well. Used by the <code><a href="">pubget</a></code>
command-line interface.</li>
</ul>
</div>


                </section>
    </main>
</body>
</html>